{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import porter as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\"the new home has been saled on top forecasts\",\n",
    "     \"the home home sales rise in july\",\n",
    "     \"there is an increase in home sales in july\",\n",
    "     \"july encounter a new home sales rise\"]\n",
    "\n",
    "stopWords=[\"the\",\"a\",\"an\",\"on\",\"behind\",\"under\",\"there\",\"in\"]\n",
    "\n",
    "index = {}\n",
    "for i in range(len(docs)):\n",
    "    index[i] = dict(Counter(map(p.stem, [word for word in (str.lower(docs[i])).split() if word not in stopWords])))           \n",
    "            \n",
    "indexInverse = {}\n",
    "for numDoc, dico in index.items():\n",
    "    for word, tf in dico.items():\n",
    "        if(word not in indexInverse):\n",
    "            indexInverse[word]= {}\n",
    "        indexInverse[word][numDoc] = tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordonnancement :\n",
    "\n",
    "pour VECTEUR\n",
    "- Utiliser index inverse pour récup pool de doc\n",
    "- ne pas mettre en vecteur els doc et la requete mais seulement comaprer les bon terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modele boolean\n",
    "req_str=\"home sales top top\"\n",
    "req = list(np.unique(list(map(p.stem, req_str.split()))))\n",
    "res=set(index)\n",
    "for stem in req:\n",
    "    res=res.intersection(indexInverse[stem])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home': 1, 'sale': 1, 'top': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter(np.unique(list(map(p.stem, req_str.split())))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter():\n",
    "    \n",
    "    def __init__(self, index, indexInverse):\n",
    "        self.index = index\n",
    "        self.indexInverse = indexInverse\n",
    "        self.idf = {}\n",
    "        self.norm = {}\n",
    "        \n",
    "    def getIdf(self, stem):\n",
    "        if(stem not in self.idf):\n",
    "            self.idf[stem] = np.log((1+len(self.index)) / (1+len(indexInverse[stem])))\n",
    "        return self.idf[stem]\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        pass\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        pass\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        pass\n",
    "    \n",
    "    def getNormDoc(self, docId):\n",
    "        #RAPPEL : norm([1,2,3])= norm([0,0,1,2,3,0]) car on va mettre au carré chaque element et le sommer.\n",
    "        #On vectorise le document \n",
    "        if(docId not in self.norm):\n",
    "            docWeights = self.getWeightsForDoc(docId)#On récupère le poids de chaque terme dans doc\n",
    "            self.norm[docId] = np.linalg.norm(list(docWeights.values()))#On récupère sous forme de list et on calcul la norm \n",
    "        return self.norm[docId]\n",
    "    \n",
    "    def getNormQuery(self, query):\n",
    "        #CF explication fonction getNormDoc\n",
    "        reqWeights = self.getWeightsForQuery(query)\n",
    "        return np.linalg.norm(list(reqWeights.values()))\n",
    "    \n",
    "    \n",
    "class Weighter1(Weighter):\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        return index[idDoc]\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        return indexInverse[stem]\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        return dict(Counter(np.unique(list(map(p.stem, query.split())))))\n",
    "    \n",
    "class Weighter2(Weighter):\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        return index[idDoc]\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        return indexInverse[stem]\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        return dict(Counter(list(map(p.stem, query.split()))))\n",
    "    \n",
    "class Weighter3(Weighter):\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        return index[idDoc]\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        return indexInverse[stem]\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        req=np.unique(list(map(p.stem, query.split())))\n",
    "        res={}\n",
    "        for stem in req:\n",
    "            res[stem] = self.getIdf(stem)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Weighter4(Weighter):\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        res={}\n",
    "        for stem in index[idDoc]:\n",
    "            res[stem] = 1+np.log(index[idDoc][stem])\n",
    "        return res\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        res={}\n",
    "        for doc in indexInverse[stem]:\n",
    "            res[doc] = 1+np.log(indexInverse[stem][doc])\n",
    "        return res\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        req=np.unique(list(map(p.stem, query.split())))\n",
    "        res={}\n",
    "        for stem in req:\n",
    "            res[stem] = self.getIdf(stem)\n",
    "        return res\n",
    "    \n",
    "\n",
    "class Weighter5(Weighter):\n",
    "    \n",
    "    def getWeightsForDoc(self, idDoc):\n",
    "        res = {}\n",
    "        for stem in index[idDoc]:\n",
    "            idf = self.getIdf(stem)\n",
    "            res[stem] = (1+np.log(index[idDoc][stem])) * idf\n",
    "        return res\n",
    "    \n",
    "    def getWeightsForStem(self, stem):\n",
    "        res={}\n",
    "        idf = self.getIdf(stem)\n",
    "        for doc in indexInverse[stem]:\n",
    "            res[doc] = (1+np.log(indexInverse[stem][doc])) * idf\n",
    "        return res\n",
    "    \n",
    "    def getWeightsForQuery(self, query):\n",
    "        tfs=dict(Counter(list(map(p.stem, query.split()))))\n",
    "        res={}\n",
    "        for stem in tfs:\n",
    "            idf = self.getIdf(stem)\n",
    "            res[stem] = (1+np.log(tfs[stem]))*idf\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarque :\n",
    "\n",
    "Le poids d'un terme n'appartenant pas à la requete sera toujours nul. Ainsi, le produit scalaire entre le vecteur de la requete et un vecteur autre ne prendra pas en compte les termes ne se trouvant pas dans la requete (multiplication par 0).\n",
    "\n",
    "Ainsi, on ne retournera pas les documents ayant un score nul (rapidité d'execution). La norme de chaque vecteur sera calculé la première fois que cela est nécessaire et garder en mémoire pour la suite.\n",
    "\n",
    "Le cosinus (= produit_scalaire(A,B) / norm(A)\\*norm(B)) ne peut etre négatif que si le produit scalaire l'est. Or das notre cas le produit scalaire sera toujours positif car les poids des termes sont toujours positifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO :\n",
    "- Faire une seule fonction getScores car il y a des redondances donc pas terribles !!! \n",
    "(on a besoin pour le cosinus d'infos comme poids de la requete qu'on a deja calculé dans fonction produit scalaire.\n",
    "en pus on réitère sur le res du produit scalaire alors qu'on pourrait faire calcul dans le prod scalaire)\n",
    "\"\"\"\n",
    "class IRModel():\n",
    "    \n",
    "    def getScores(query):\n",
    "        pass\n",
    "    \n",
    "    def getRanking(query):\n",
    "        return sorted(list(zip(query.keys(),query.values())), key=lambda e : e[1])\n",
    "\n",
    "class Vectoriel(IRModel):\n",
    "    \n",
    "    def __init__(self, weighter, normalized):\n",
    "        self.weighter = weighter\n",
    "        self.normalized = normalized\n",
    "        \n",
    "    def getScores(self, query):\n",
    "        if(self.normalized == True):#Cosinus\n",
    "            return getScoresNormalized(query)\n",
    "        else:#produit scalaire\n",
    "            return getScoresNotNormalized(query)\n",
    "        \n",
    "    def getScoresNormalized(self, query):\n",
    "        \"\"\"\n",
    "        Permet de récupérer le score en utilisant le cosinus entre les représentations vectorielles des documents\n",
    "        \"\"\"\n",
    "        #cos(A,B)= A.B / (||A||.||B||) où v.w est le produit scalaire de v et w et ||v|| est la norme de v\n",
    "        prodScalaires = self.getScoresNotNormalized(query)#Le produit scalaire est le résultat de l'autre fonction\n",
    "        res={}\n",
    "        for docId,prod in prodScalaires.items():#Pour chaque produit scalaire, on divise par le produit des norm\n",
    "            res[docId] = prod/(self.weighter.getNormDoc(docId)*self.weighter.getNormQuery(query))\n",
    "        return res\n",
    "    \n",
    "    def getScoresNotNormalized(self, query):\n",
    "        \"\"\"\n",
    "        Permet de récupérer le score en utilisant le produit scalaire entre les représentations vectorielles des documents\n",
    "        \"\"\"\n",
    "        reqWeights = self.weighter.getWeightsForQuery(query)\n",
    "        res={}\n",
    "        for stem,weightStem in reqWeights.items():\n",
    "            docWeights = self.weighter.getWeightsForStem(stem)\n",
    "            for docId,weightDoc in docWeights.items():\n",
    "                if(docId not in res):\n",
    "                    res[docId] = weightStem*weightDoc\n",
    "                else:\n",
    "                    res[docId] += weightStem*weightDoc\n",
    "        #Mono ligne avec dictionnaire de comprehension ?         \n",
    "        return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 30), (2, 20)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query={1:30,2:20}\n",
    "sorted(list(zip(query.keys(),query.values())), key=lambda e : e[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1  | v: 10\n",
      "k: 2  | v: 20\n",
      "k: 3  | v: 30\n"
     ]
    }
   ],
   "source": [
    "d={1:10,2:20,3:30}\n",
    "for (k,v) in d.items():\n",
    "    print(\"k:\",k,\" | v:\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.416573867739416"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(list(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 4, 4, 6, 6, 8, 8, 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i if i%2==0 else i+1 for i in range(0,10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
