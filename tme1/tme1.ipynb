{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import porter as p\n",
    "import TextRepresenter as tr\n",
    "from collections import Counter\n",
    "pt=tr.PorterStemmer()\n",
    "\n",
    "from Parser import Parser\n",
    "from IndexerSimple import IndexerSimple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\"the new home has been saled on top forecasts\",\n",
    "     \"the home sales rise in july\",\n",
    "     \"there is an increase in home sales in july\",\n",
    "     \"july encounter a new home sales rise\"]\n",
    "\n",
    "stopWords=[\"the\",\"a\",\"an\",\"on\",\"behind\",\"under\",\"there\",\"in\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home': 1, 'sale': 1, 'rise': 1, 'juli': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#en minuscule\n",
    "tmp1=str.lower(docs[1])\n",
    "#sépare les mots\n",
    "tmp2=tmp1.split()\n",
    "#enlève les stopWords\n",
    "tmp3=[word for word in tmp2 if word not in stopWords]\n",
    "#applique la radicalisation sur chaque mot\n",
    "tmp4=map(p.stem, tmp3)\n",
    "#coompte les éléments et convertit en dictionnaire\n",
    "dict(Counter(tmp4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'new': 1,\n",
       "  'home': 1,\n",
       "  'ha': 1,\n",
       "  'been': 1,\n",
       "  'sale': 1,\n",
       "  'top': 1,\n",
       "  'forecast': 1},\n",
       " 1: {'home': 1, 'sale': 1, 'rise': 1, 'juli': 1},\n",
       " 2: {'is': 1, 'increas': 1, 'home': 1, 'sale': 1, 'juli': 1},\n",
       " 3: {'juli': 1, 'encount': 1, 'new': 1, 'home': 1, 'sale': 1, 'rise': 1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {}\n",
    "for i in range(len(docs)):\n",
    "    index[i] = dict(Counter(map(p.stem, [word for word in (str.lower(docs[i])).split() if word not in stopWords])))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new': {0: 1, 3: 1},\n",
       " 'home': {0: 1, 1: 1, 2: 1, 3: 1},\n",
       " 'ha': {0: 1},\n",
       " 'been': {0: 1},\n",
       " 'sale': {0: 1, 1: 1, 2: 1, 3: 1},\n",
       " 'top': {0: 1},\n",
       " 'forecast': {0: 1},\n",
       " 'rise': {1: 1, 3: 1},\n",
       " 'juli': {1: 1, 2: 1, 3: 1},\n",
       " 'is': {2: 1},\n",
       " 'increas': {2: 1},\n",
       " 'encount': {3: 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexInverse = {}\n",
    "for numDoc in index:\n",
    "    for word in index[numDoc]:\n",
    "        if(word not in indexInverse):\n",
    "            indexInverse[word]= {}\n",
    "        if(numDoc not in indexInverse[word]):\n",
    "            indexInverse[word][numDoc]=1\n",
    "        else:\n",
    "            indexInverse[word][numDoc]+=1\n",
    "indexInverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new': 2,\n",
       " 'home': 4,\n",
       " 'ha': 1,\n",
       " 'been': 1,\n",
       " 'sale': 4,\n",
       " 'top': 1,\n",
       " 'forecast': 1,\n",
       " 'rise': 2,\n",
       " 'juli': 3,\n",
       " 'is': 1,\n",
       " 'increas': 1,\n",
       " 'encount': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df={}\n",
    "for word in indexInverse:\n",
    "    df[word]=len(indexInverse[word])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'new': 0.5108256237659907,\n",
       "  'home': 0.0,\n",
       "  'ha': 0.9162907318741551,\n",
       "  'been': 0.9162907318741551,\n",
       "  'sale': 0.0,\n",
       "  'top': 0.9162907318741551,\n",
       "  'forecast': 0.9162907318741551},\n",
       " 1: {'home': 0.0,\n",
       "  'sale': 0.0,\n",
       "  'rise': 0.5108256237659907,\n",
       "  'juli': 0.22314355131420976},\n",
       " 2: {'is': 0.9162907318741551,\n",
       "  'increas': 0.9162907318741551,\n",
       "  'home': 0.0,\n",
       "  'sale': 0.0,\n",
       "  'juli': 0.22314355131420976},\n",
       " 3: {'juli': 0.22314355131420976,\n",
       "  'encount': 0.9162907318741551,\n",
       "  'new': 0.5108256237659907,\n",
       "  'home': 0.0,\n",
       "  'sale': 0.0,\n",
       "  'rise': 0.5108256237659907}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = {}\n",
    "for numDoc in index:\n",
    "    tf_idf[numDoc] = {}\n",
    "    for word in index[numDoc]:\n",
    "        tf_idf[numDoc][word] = index[numDoc][word] * np.log( (1+len(index)) / (1+df[word]) )\n",
    "        \n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDocCollectionSimple(chemin):\n",
    "    \n",
    "    res = {}\n",
    "    currentI = None\n",
    "    isInT = False\n",
    "    \n",
    "    file = open(chemin, 'r') \n",
    "    \n",
    "    while True:\n",
    "        #lis une seule ligne\n",
    "        line = file.readline()\n",
    "        \n",
    "        #si ligne vide, fin du fichier\n",
    "        if not line:\n",
    "            break\n",
    "            \n",
    "        #récupère la ligne sous forme de mots\n",
    "        words=line.split()\n",
    "        \n",
    "        #Si la ligne n'est pas vide\n",
    "        if(len(words)>0):\n",
    "            #si c'est une balise I\n",
    "            if(words[0]==\".I\"):\n",
    "                res[words[1]] = \"\" #Je créé le dictionnaire pour ce document\n",
    "                currentI = words[1] #Je garde l'identifiant du document courant\n",
    "                isInT=False #J'indique que je ne suis pas danc une balise T\n",
    "            #Sinon si c'est une balise T\n",
    "            elif(words[0]==\".T\"):\n",
    "                isInT=True #J'indique que je suis danc une balise T\n",
    "            else:\n",
    "                #Sinon si c'est une autre balise\n",
    "                if(words[0][0]=='.'):\n",
    "                    isInT=False #J'indique que je ne suis pas danc une balise T\n",
    "                else:\n",
    "                    #Sinon si on est dans .I et dans .T\n",
    "                    if(isInT==True and currentI != None):\n",
    "                        res[currentI] += line #J'ajoute la ligne courante au texte du document courant\n",
    "        \n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Preliminary Report-International Algebraic Language\\njgkfldjgfkld\\n',\n",
       " '2': 'Extraction of Roots by Repeated Subtractions for Digital Computers\\n',\n",
       " '3': 'Techniques Department on Matrix Program Schemes\\n',\n",
       " '4': 'Glossary of Computer Engineering and Programming Terminology\\n',\n",
       " '5': 'Two Square-Root Approximations\\n',\n",
       " '6': 'The Use of Computers in Inspection Procedures\\n',\n",
       " '7': 'Glossary of Computer Engineering and Programming Terminology\\n',\n",
       " '8': 'On The Equivalence and Transformation of Program Schemes\\n',\n",
       " '9': 'Proposal for an UNCOL\\n',\n",
       " '10': 'Glossary of Computer Engineering and Programming Terminology\\n',\n",
       " '11': 'The Problem of Programming Communication with\\nChanging Machines A Proposed Solution-Part 2\\n'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildDocCollectionSimple('cacmShort-good.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDocumentCollectionRegex(chemin):\n",
    "    \n",
    "    file = open(chemin, 'r') \n",
    "    \n",
    "    lines = file.read()\n",
    "    #regex = re.compile(r'.I (\\w+?)\\n(?:\\.T\\n([\\w\\d\\s-]+))?')\n",
    "    regex = re.compile(r'\\.I (\\d+)\\n(?:\\.T\\n([\\w\\s.-]+?)\\n\\.)?')\n",
    "    res = dict(regex.findall(lines))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Preliminary Report-International Algebraic Language\\njgkfldjgfkld',\n",
       " '2': 'Extraction of Roots by Repeated Subtractions for Digital Computers',\n",
       " '3': 'Techniques Department on Matrix Program Schemes',\n",
       " '4': 'Glossary of Computer Engineering and Programming Terminology',\n",
       " '5': 'Two Square-Root Approximations',\n",
       " '6': 'The Use of Computers in Inspection Procedures',\n",
       " '7': 'Glossary of Computer Engineering and Programming Terminology',\n",
       " '8': 'On The Equivalence and Transformation of Program Schemes',\n",
       " '9': 'Proposal for an UNCOL',\n",
       " '10': 'Glossary of Computer Engineering and Programming Terminology',\n",
       " '11': 'The Problem of Programming Communication with\\nChanging Machines A Proposed Solution-Part 2'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildDocumentCollectionRegex('cacmShort-good.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF Document.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF Parser.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalement, une classe parser par collection (veut dire? un parserCamc, un parserCisi ?)\n",
    "<br/><br/>\n",
    "La fonction parse ci dessous ne vériie pas que chaque document a un identifiant unique (peut etre vérifié en utilisant un set d'identifiant commun aux instances par ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour parser, voici carac balise:\n",
    "- titre = plusieurs lignes de texte\n",
    "- texte = plusieurs lignes de textes\n",
    "- date = 4 digit ou texte puis 4 digit (donc regex sur 4 digit)\n",
    "- auteur = nom, prénom1 prenom2 etc (les prénoms sont espacé et peuvent etre de la forme A.). Un auteur par ligne. Pas forcément d'espace entre nom \",\" et prénom\n",
    "- mots = plusieurs mots/expressions séparés par une virgule sur plusieurs ligne (mot1 mot2, mot3, mot4 mot5 mot6)\n",
    "- liens = plusieurs ligne et sur chaque ligne: number1    number2    number3 (3 nombres séparé par 'tab') mais seul premier intéressant (id du truc cité ou du truc qui cite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 4) 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF InderxerSimple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6)\n",
    "TODO : mettre les 3 lignes de codes suivante dans fichiers Test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collec1 = Parser.parseCacmCisi('cisi/cisi.txt')\n",
    "indexer=IndexerSimple(collec1)\n",
    "indexer.indexation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
